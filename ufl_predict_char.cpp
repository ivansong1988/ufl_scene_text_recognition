#include <opencv2/opencv.hpp>
#include <iostream>
#include <fstream>

#include "utils.h"

#include <stdio.h>
#include <ctype.h>
#include <stdlib.h>
#include <string.h>
#include <errno.h>
#include "linear.h"


using namespace cv;
using namespace std;


int main(int argc, char **argv)
{

struct model* model_;

  // first argument is liblinear model
  // second argument is 1st layer filter bank
  // third argument is an image

  if((model_=load_model(argv[1]))==0)
  {
    fprintf(stderr,"can't open model file %s\n",argv[1]);
    exit(1);
  }


  // Load filters bank and withenning params
  Mat filters, M, P;
  FileStorage fs(argv[2], FileStorage::READ);
  fs["D"] >> filters;
  fs["M"] >> M;
  fs["P"] >> P;
  fs.release();

  int image_size  = 32;
  int quad_size   = 12;
  int patch_size  = 8;
  int num_quads   = 25; // extract 25 quads (12x12) from each image
  int num_tiles   = 25; // extract 25 patches (8x8) from each quad 

  double alpha    = 0.5; // used for feature representation: 
                         // scalar non-linear function z = max(0, |D*a| - alpha)


  Mat quad;
  Mat tmp;

  // TODO begin loop foreach detection window
    int patch_count = 0;
    vector< vector<double> > data_pool(9); 
    Mat img  = imread(argv[3]);
    if(img.channels() != 3)
    {
      cout << "ERROR: image must be RGB" << endl;
      exit(-1);
    }
    cvtColor(img,img,COLOR_RGB2GRAY);
    double t = (double)cvGetTickCount();
    resize(img,img,Size(image_size,image_size));

    int quad_id = 1;
    for (int q_x=0; q_x<=image_size-quad_size; q_x=q_x+(quad_size/2-1))
    {
      for (int q_y=0; q_y<=image_size-quad_size; q_y=q_y+(quad_size/2-1))
      {
        Rect quad_rect = Rect(q_x,q_y,quad_size,quad_size); 
        img(quad_rect).copyTo(quad);

        //start sliding window (8x8) in each tile and store the patch as row in data_pool
        for (int w_x=0; w_x<=quad_size-patch_size; w_x++)
        {
          for (int w_y=0; w_y<=quad_size-patch_size; w_y++)
          {
            quad(Rect(w_x,w_y,patch_size,patch_size)).copyTo(tmp);
            tmp = tmp.reshape(0,1);
            tmp.convertTo(tmp, CV_64F);
            normalizeAndZCA(tmp,M,P);
            vector<double> patch;
            tmp.copyTo(patch);
            if ((quad_id == 1)||(quad_id == 2)||(quad_id == 6)||(quad_id == 7))
              data_pool[0].insert(data_pool[0].end(),patch.begin(),patch.end());
            if ((quad_id == 2)||(quad_id == 7)||(quad_id == 3)||(quad_id == 8)||(quad_id == 4)||(quad_id == 9))
              data_pool[1].insert(data_pool[1].end(),patch.begin(),patch.end());
            if ((quad_id == 4)||(quad_id == 9)||(quad_id == 5)||(quad_id == 10))
              data_pool[2].insert(data_pool[2].end(),patch.begin(),patch.end());
            if ((quad_id == 6)||(quad_id == 11)||(quad_id == 16)||(quad_id == 7)||(quad_id == 12)||(quad_id == 17))
              data_pool[3].insert(data_pool[3].end(),patch.begin(),patch.end());
            if ((quad_id == 7)||(quad_id == 12)||(quad_id == 17)||(quad_id == 8)||(quad_id == 13)||(quad_id == 18)||(quad_id == 9)||(quad_id == 14)||(quad_id == 19))
              data_pool[4].insert(data_pool[4].end(),patch.begin(),patch.end());
            if ((quad_id == 9)||(quad_id == 14)||(quad_id == 19)||(quad_id == 10)||(quad_id == 15)||(quad_id == 20))
              data_pool[5].insert(data_pool[5].end(),patch.begin(),patch.end());
            if ((quad_id == 16)||(quad_id == 21)||(quad_id == 17)||(quad_id == 22))
              data_pool[6].insert(data_pool[6].end(),patch.begin(),patch.end());
            if ((quad_id == 17)||(quad_id == 22)||(quad_id == 18)||(quad_id == 23)||(quad_id == 19)||(quad_id == 24))
              data_pool[7].insert(data_pool[7].end(),patch.begin(),patch.end());
            if ((quad_id == 19)||(quad_id == 24)||(quad_id == 20)||(quad_id == 25))
              data_pool[8].insert(data_pool[8].end(),patch.begin(),patch.end());
            patch_count++;
          }
        }

        quad_id++;
      }
    }

    //do dot product of each normalized and whitened patch 
    //each pool is averaged and this yields a representation of 9xD 
    Mat feature = Mat::zeros(9,filters.rows,CV_64FC1);
    for (int i=0; i<9; i++)
    {
      Mat pool = Mat(data_pool[i]);
      pool = pool.reshape(0,data_pool[i].size()/filters.cols);
      for (int p=0; p<pool.rows; p++)
      {
        for (int f=0; f<filters.rows; f++)
        {
          feature.row(i).at<double>(0,f) = feature.row(i).at<double>(0,f) + max(0.0,std::abs(pool.row(p).dot(filters.row(f)))-alpha);
        }
      }
    }
    feature = feature.reshape(0,1);


    // data must be normalized within the range obtained during training
    double lower = -1.0;
    double upper =  1.0;
    Mat feature_min = Mat::zeros(1,feature.cols,CV_64FC1);
    Mat feature_max = (Mat_<double>(1,feature.cols) << 290.579, 288.077, 317.623, 220.961, 271.661, 183.959, 254.074, 291.813, 206.024, 186.538, 115.593, 335.006, 307.17, 215.473, 306.91, 209.844, 308.082, 117.292, 280.05, 122.882, 396.76, 346.702, 178.015, 141.719, 206.39, 222.667, 94.577, 304.801, 238.871, 290.002, 175.347, 248.74, 208.005, 289, 194.929, 248.434, 194.761, 269.097, 225.29, 162.15, 155.753, 209.466, 175.332, 267.797, 200.205, 281.487, 256.784, 372.141, 183.987, 351.264, 248.445, 196.957, 171.831, 255.358, 274.194, 199.48, 206.842, 325.014, 162.068, 219.923, 226.624, 231.098, 160.463, 174.704, 184.599, 134.555, 388.461, 161.329, 304.53, 176.413, 188.372, 176.85, 285.629, 129.174, 365.428, 278.251, 331.249, 227.714, 346.131, 231.354, 352.546, 201.266, 179.273, 236.34, 107.191, 287.258, 273.899, 263.948, 207.891, 307.548, 167.858, 162.404, 215.743, 189.299, 152.674, 268.795, 356.257, 199.297, 283.152, 207.96, 332.108, 358.504, 242.658, 230.389, 140.572, 183.884, 292.941, 198.829, 219.38, 168.235, 221.574, 420.013, 356.951, 318.549, 276.62, 428.724, 261.78, 301.94, 302.113, 300.7, 276.457, 141.068, 476.642, 278.669, 303.263, 350.734, 335.819, 382.519, 167.371, 388.6, 169.739, 430.256, 604.3099999999999, 239.624, 215.967, 299.406, 246.864, 138.77, 431.966, 318.001, 503.2, 277.432, 331.15, 346.231, 535.842, 289.075, 403.327, 258.577, 338.054, 254.712, 265.931, 263.204, 265.413, 203.027, 344.961, 246.87, 389.455, 356.419, 566.578, 269.673, 636.98, 251.426, 287.552, 254.111, 406.768, 415.338, 287.781, 218.929, 404.423, 244.538, 299.343, 277.813, 305.121, 261.115, 252.313, 179.213, 188.633, 531.266, 203.503, 417.135, 183.875, 174.603, 231.067, 459.653, 213.533, 500.627, 354.697, 425.907, 296.099, 464.837, 348.74, 499.667, 321.573, 284.43, 286.213, 169.618, 428.283, 302.267, 413.5, 304.15, 421.945, 252.601, 304.849, 303.686, 308.819, 218.156, 262.009, 672.477, 226.793, 419.863, 303.855, 445.507, 543.4160000000001, 263.643, 350.159, 236.179, 281.715, 398.736, 203.993, 292.916, 227.69, 315.21, 264.729, 258.461, 265.497, 191.746, 244.979, 313.469, 223.992, 245.59, 221.619, 266.622, 91.16370000000001, 315.359, 226.116, 188.337, 305.66, 216.155, 282.323, 109.139, 234.194, 120.074, 290.846, 390.186, 194.571, 227.924, 192.989, 233.594, 104.593, 248.416, 191.208, 290.986, 177.242, 211.476, 232.391, 320.531, 195.153, 259.823, 156.863, 269.897, 212.929, 247.743, 191.211, 191.049, 244.462, 201.907, 281.617, 250.515, 259.293, 340.325, 191.285, 357.713, 188.922, 182.112, 261.15, 310.07, 219.739, 165.559, 292.986, 243.775, 153.462, 273.111, 217.763, 181.214, 162.8, 156.332, 135.553, 137.221, 339.091, 155.612, 275.976, 168.718, 125.221, 224.765, 311.337, 176.916, 274.969, 265.061, 337.678, 220.308, 269.395, 199.797, 325.763, 236.637, 259.65, 231.897, 170.703, 265.819, 213.04, 310.339, 186.37, 235.638, 148.409, 203.087, 153.623, 215.439, 172.003, 195.462, 322.571, 195.05, 259.589, 197.443, 260.933, 339.451, 146.971, 193.53, 141.733, 161.089, 244.963, 140.316, 196.49, 133.383, 255.464, 392.44, 337.527, 303.107, 252.646, 367.562, 268.397, 322.991, 321.939, 301.743, 360.571, 146.775, 378.246, 337.764, 374.311, 333.087, 307.233, 351.697, 162.343, 334.628, 188.752, 432.252, 520.782, 237.869, 261.391, 329.533, 256.148, 142.662, 394.128, 285.125, 381.808, 240.788, 339.87, 290.231, 436.721, 348.083, 351.863, 316.382, 386.043, 382.622, 313.884, 298.748, 295.214, 226.545, 321.196, 278.558, 355.055, 344.82, 476.464, 249.354, 525.034, 413.224, 280.809, 265.666, 343.23, 299.722, 292.082, 270.68, 391.123, 225.728, 443.785, 342.82, 326.465, 217.105, 244.86, 302.48, 214.194, 507.678, 149.216, 464.822, 177.902, 330.457, 339.706, 395.251, 218.515, 460.914, 333.05, 324.969, 197.886, 425.372, 354.127, 444.822, 303.363, 281.092, 303.91, 190.321, 416.698, 372.509, 316.813, 267.997, 387.073, 208.778, 339.172, 261.878, 257.796, 278.706, 419.617, 567.529, 359.694, 369.639, 266.085, 466.95, 531.801, 270.622, 251.757, 240.231, 275.339, 432.11, 244.622, 326.42, 263.447, 289.395, 577.605, 500.125, 505.981, 368.142, 584.569, 449.934, 434.008, 494.964, 440.894, 398.49, 196.93, 779.639, 584.823, 429.378, 544.518, 492.986, 533.354, 246.505, 500.243, 273.867, 704.693, 859.6079999999999, 402.694, 438.37, 458.88, 446.752, 198.506, 642.871, 423.947, 675.124, 398.936, 589.827, 465.846, 861.849, 429.823, 533.027, 498.639, 587.3099999999999, 521.55, 512.444, 401.904, 476.53, 356.233, 552.645, 428.919, 511.289, 506.311, 797.891, 420.186, 1025.78, 425.416, 433.487, 355.046, 649.1609999999999, 462.245, 422.768, 419.494, 639.003, 357.66, 443.829, 464.178, 424.488, 345.211, 396.414, 273.115, 304.684, 834.772, 301.263, 663.855, 272.42, 285.138, 517.801, 644.7809999999999, 417.901, 746.942, 498.381, 505.088, 407.214, 717.237, 545.458, 752.825, 446.549, 469.004, 482.23, 321.958, 706.657, 465.078, 589.1369999999999, 435.187, 574.481, 332.942, 393.682, 395.272, 448.709, 300.481, 462.322, 834.2089999999999, 344.58, 588.36, 450.601, 616.659, 757.821, 369.356, 381.27, 352.058, 413.354, 677.371, 308.792, 522.2190000000001, 307.894, 401.108, 337.138, 390.021, 415.975, 283.484, 349.672, 459.063, 220.439, 346.271, 307.214, 298.825, 120.665, 513.345, 371.993, 229.586, 387.869, 325.386, 346.101, 148.962, 317.052, 232.213, 507.278, 542.191, 326.819, 361.009, 214.901, 384.129, 150.08, 374.096, 251.573, 401.103, 300.526, 303.562, 384.508, 456.581, 282.235, 407.684, 311.163, 312.453, 280.531, 367.41, 267.824, 320.522, 412.931, 370.944, 390.581, 405.693, 277.854, 526.716, 288.26, 594.533, 265.775, 264.594, 313.004, 401.815, 272.192, 242.166, 488.655, 336.132, 218.632, 300.133, 234.276, 235.343, 202.784, 300.596, 193.582, 217.52, 469.929, 180.857, 435.79, 294.582, 151.756, 300.176, 467.535, 201.516, 424.803, 347.544, 372.341, 274.433, 352.696, 434.683, 404.278, 333.271, 458.906, 333.634, 308.458, 446.449, 332.452, 396.256, 235.118, 454.269, 238.392, 222.422, 254.663, 319.923, 213.541, 230.496, 532.134, 275.906, 384.304, 271.042, 431.487, 494.281, 245.488, 258.684, 291.24, 233.689, 370.771, 213.566, 388.931, 194.771, 312.777, 338.477, 230.109, 311.191, 198.51, 270.043, 175.317, 227.218, 204.93, 200.24, 230.775, 118.727, 294.4, 337.796, 254.795, 319.105, 212.192, 292.184, 126.204, 243.329, 126.852, 335.437, 336.387, 183.841, 178.545, 251.369, 207.968, 101.109, 321.775, 223.301, 259.3, 202.044, 230.594, 235.906, 323.382, 200.727, 206.535, 185.333, 365.302, 193.913, 199.831, 186.371, 195.192, 164.62, 237.339, 177.792, 241.624, 234.958, 387.665, 184.197, 369.144, 231.309, 194.391, 174.744, 214.273, 254.319, 195.498, 196.375, 303.847, 148.998, 274.424, 229.702, 210.427, 149.485, 159.019, 173.138, 138.179, 392.254, 113.868, 295.823, 179.615, 195.808, 203.2, 265.631, 193.334, 328.295, 214.538, 340.725, 166.739, 319.095, 227.462, 354.296, 228.738, 210.702, 192.839, 146.862, 262.196, 255.108, 243, 203.421, 270.675, 164.63, 208.98, 208.069, 242.699, 170.333, 191.698, 445.59, 211.842, 258.529, 172.851, 280.883, 399.563, 226.71, 197.961, 140.748, 199.554, 304.851, 163.764, 222.195, 182.775, 176.704, 366.958, 388.439, 434.55, 290.299, 411.075, 287.043, 281.65, 263.171, 295.056, 274.619, 147.555, 552.5839999999999, 362.494, 323.994, 431.298, 341.708, 411.646, 137.199, 345.639, 161.826, 480.506, 595.852, 241.356, 209.174, 431.2, 250.012, 132.439, 453.691, 314.602, 425.048, 288.061, 354.721, 402.281, 557.854, 271.57, 328.925, 282.068, 352.182, 259.791, 245.355, 271.09, 262.312, 232.791, 336.935, 250.839, 371.086, 329.47, 577.524, 295.047, 671.837, 244.271, 302.759, 262.142, 354.179, 314.975, 270.362, 262.437, 446.367, 231.804, 295.285, 280.463, 311.593, 218.14, 228.964, 167.67, 197.536, 712.647, 166.933, 485.043, 260.252, 177.975, 261.334, 461.461, 268.059, 486.067, 340.76, 451.864, 220.671, 493.442, 313.994, 588.672, 334.342, 233.745, 273.994, 146.085, 401.106, 307.747, 447.116, 315.572, 415.649, 210.669, 299.338, 253.302, 326.039, 220.158, 248.596, 630.519, 213.534, 404.595, 262.464, 419.448, 568.619, 266.042, 264.615, 218.158, 283.315, 457.542, 205.45, 283.104, 226.286, 265.388, 278.717, 281.683, 342.546, 172.522, 251.189, 319.441, 236.174, 240.871, 226.309, 259.969, 95.7807, 327.395, 321.885, 210.859, 293.24, 236.586, 256.924, 102.443, 220.084, 157.034, 316.404, 378.462, 184.29, 227.456, 208.884, 228.613, 105.148, 274.829, 202.808, 241.561, 204.072, 228.691, 315.501, 322.044, 216.241, 251.892, 187.16, 303.591, 198.476, 241.05, 215.465, 193.285, 236.994, 217.213, 271.809, 237.466, 269.807, 360.555, 191.404, 381.315, 170.106, 181.75, 258.963, 262.254, 225.743, 160.061, 291.447, 256.803, 156.846, 263.964, 224.729, 171.614, 150.291, 191.589, 125.41, 138.872, 471.581, 130.838, 311.035, 209.755, 113.066, 212.706, 291.119, 176.867, 308.598, 282.904, 364.449, 189.332, 268.046, 265.674, 324.639, 252.753, 274.533, 213.937, 180.413, 269.967, 256.913, 302.246, 187.764, 263.662, 161.593, 214.547, 172.407, 210.77, 167.612, 179.166, 378.462, 177.524, 258.802, 154.079, 274.918, 367.186, 211.056, 178.501, 162.978, 157.051, 272.541, 132.588, 257.906, 135.792, 196.881 );
    for (int k=0; k<feature.cols; k++)
    {
      if(feature.at<double>(0,k) == feature_min.at<double>(0,k))
        feature.at<double>(0,k) = lower;
      else if(feature.at<double>(0,k) == feature_max.at<double>(0,k))
        feature.at<double>(0,k) = upper;
      else   
        feature.at<double>(0,k) = lower + (upper-lower) *
                                  (feature.at<double>(0,k)-feature_min.at<double>(0,k))/
                                  (feature_max.at<double>(0,k)-feature_min.at<double>(0,k));
    }

    struct feature_node *x = (struct feature_node *) 
                             malloc((feature.cols+1)*sizeof(struct feature_node));

    for (int k=0; k<feature.cols; k++)
    {
       x[k].index = k+1; // liblinear labels start at 1 not 0
       x[k].value = feature.at<double>(0,k);
    }
    x[feature.cols].index = -1;

    t = cvGetTickCount() - t;
    cout << " Feature extraction done in " << t/((double)cvGetTickFrequency()*1000.) << " ms." << endl;
    t = (double)cvGetTickCount();

    double predict_label = predict(model_,x);
    fprintf(stdout,"Prediction: %g\n",predict_label);
    string ascii = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyx0123456789";
    fprintf(stdout,"Character : %c\n",ascii[predict_label-1]);
    t = cvGetTickCount() - t;
    cout << " Classification done in " << t/((double)cvGetTickFrequency()*1000.) << " ms." << endl;

  
  // TODO end for each detection window


  imshow("image",img);
  waitKey(-1);
  free_and_destroy_model(&model_);
  free(x);
  return 0;
}
